{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshih8/recipes/blob/main/Prepare_the_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfce8dcb",
      "metadata": {
        "id": "cfce8dcb"
      },
      "outputs": [],
      "source": [
        "pip install torchvision\n",
        "\n",
        "\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E_ztvTz71QZa",
      "metadata": {
        "id": "E_ztvTz71QZa"
      },
      "outputs": [],
      "source": [
        "pip install --ignore-installed Pillow==9.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600285c5",
      "metadata": {
        "id": "600285c5"
      },
      "outputs": [],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f6f619",
      "metadata": {
        "id": "d6f6f619"
      },
      "outputs": [],
      "source": [
        "pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1SOu_evlySXi",
      "metadata": {
        "id": "1SOu_evlySXi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f86e8b",
      "metadata": {
        "id": "04f86e8b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "HOME_PATH = os.path.expanduser(f'~')\n",
        "USERNAME = os.path.split(HOME_PATH)[1]\n",
        "\n",
        "\n",
        "dataroot = '/content/drive/MyDrive/Images'\n",
        "ref = '/content/drive/MyDrive/FETAL_PLANES_DB_data.csv'\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f'Device: {device}')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 500) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c11dda",
      "metadata": {
        "id": "b6c11dda"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57300021",
      "metadata": {
        "id": "57300021"
      },
      "outputs": [],
      "source": [
        "class FetalPlaneDataset(Dataset):\n",
        "    \"\"\"Fetal Plane dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, ref, \n",
        "                 plane, \n",
        "                 brain_plane=None, \n",
        "                 us_machine=None, \n",
        "                 operator_number=None, \n",
        "                 transform=None\n",
        "                ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            plane: 'Fetal brain'; 'Fetal thorax'; 'Maternal cervix'; 'Fetal femur'; 'Fetal thorax'; 'Other'\n",
        "            brain_plane: 'Trans-ventricular'; 'Trans-thalamic'; 'Trans-cerebellum'\n",
        "            us_machine: 'Voluson E6';'Voluson S10'\n",
        "            operator_number: 'Op. 1'; 'Op. 2'; 'Op. 3';'Other'\n",
        "            \n",
        "        return image\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.ref = pd.read_csv(ref, sep=';')\n",
        "        self.ref = self.ref[self.ref['Plane'] == plane]\n",
        "        if plane == 'Fetal brain':\n",
        "            self.ref = self.ref[self.ref['Brain_plane'] == brain_plane]\n",
        "        if us_machine is not None:\n",
        "            self.ref = self.ref[self.ref['US_Machine'] == us_machine]\n",
        "        if operator_number is not None:\n",
        "            self.ref = self.ref[self.ref['Operator'] == operator_number]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ref)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        #print(f'idx: {idx} \\n')\n",
        "        #print(f'self.ref.iloc[idx, 0]: {self.ref.iloc[idx, 0]} \\n')\n",
        "       \n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.ref.iloc[idx, 0] + '.png')\n",
        "        #print(img_name)\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        \n",
        "        #print(type(image))\n",
        "        #print(image.dtype)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db8748c2",
      "metadata": {
        "id": "db8748c2"
      },
      "source": [
        "# Prepare training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbfdef0",
      "metadata": {
        "id": "5bbfdef0"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "#dataroot = FULL_DATA_REPO_PATH + \"fetal_planes/Images\"\n",
        "#ref = FULL_DATA_REPO_PATH + \"FETAL_PLANES_DB_data.csv\"\n",
        "\n",
        "##Plane\n",
        "# plane = 'Fetal brain'\n",
        "plane = 'Fetal thorax'\n",
        "#plane = 'Maternal cervix'\n",
        "# plane = 'Fetal femur'\n",
        "# plane = 'Fetal thorax'\n",
        "# plane = 'Other'\n",
        "\n",
        "#operator_number = None\n",
        "#operator_number = 'Op. 1'\n",
        "#operator_number = 'Op. 2'\n",
        "#operator_number = 'Op. 3'\n",
        "operator_number = 'Other'\n",
        "\n",
        "us_machine = None\n",
        "#us_machine = 'Voluson E6'\n",
        "#us_machine = 'Voluson S10'\n",
        "\n",
        "brain_plane = None\n",
        "# brain_plane = 'Trans-ventricular'; us_machine = 'Voluson E6' ###len: 408 \n",
        "#brain_plane = 'Trans-ventricular';us_machine = 'Voluson S10' ###len: 59 \n",
        "#brain_plane = 'Trans-ventricular'; us_machine = 'Aloka' ###len: 112 \n",
        "# brain_plane = 'Trans-ventricular'; us_machine = 'Other' ###len: 18\n",
        "\n",
        "# brain_plane = 'Trans-thalamic'; us_machine = 'Voluson E6' ###len: 1072 \n",
        "# brain_plane = 'Trans-thalamic'; us_machine = 'Voluson S10' ###len: 123 \n",
        "# brain_plane = 'Trans-thalamic'; us_machine = 'Aloka' ###len: 360 \n",
        "# brain_plane = 'Trans-thalamic'; us_machine = 'Other' ###len: 83 \n",
        "\n",
        "# brain_plane = 'Trans-cerebellum'; us_machine = 'Voluson E6' ###len: 492 \n",
        "# brain_plane = 'Trans-cerebellum'; us_machine = 'Voluson S10' ###len: 68 \n",
        "# brain_plane = 'Trans-cerebellum'; us_machine = 'Aloka' ###len: 134 \n",
        "# brain_plane = 'Trans-cerebellum'; us_machine = 'Other' ###len: 20 \n",
        "\n",
        "\n",
        "#image_size = 28\n",
        "# image_size = 32\n",
        "#image_size = 64\n",
        "image_size = 128\n",
        "#image_size = 512\n",
        "\n",
        "# Number of workers for dataloader 设置成0避免报错\n",
        "workers = 1\n",
        "\n",
        "# Batch size during training\n",
        "#batch_size = 2\n",
        "#batch_size = 3\n",
        "#batch_size = 4\n",
        "batch_size = 8\n",
        "#batch_size = 16\n",
        "#atch_size = 128\n",
        "\n",
        "SHUFFLE_T = True\n",
        "SHUFFLE_F = False\n",
        "\n",
        "#preprocess\n",
        "transform_operations = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.RandomHorizontalFlip(),  # Randomly flip (data augmentation)\n",
        "                        #mt.RandRotate(range_x=0.1, prob=0.5),\n",
        "                        #mt.RandZoom(prob=0.5, min_zoom=1, max_zoom=1.1),\n",
        "                        #mt.Resize([image_size, image_size]),\n",
        "                        transforms.Resize([image_size, image_size]),# Resize\n",
        "                        transforms.Normalize((0.5,), (0.5,)), #mean=0.5, std=0.5\n",
        "                        ])\n",
        "\n",
        "dataset = FetalPlaneDataset(root_dir=dataroot, \n",
        "                            ref=ref,\n",
        "                            plane=plane,\n",
        "                            brain_plane=brain_plane,\n",
        "                            us_machine=us_machine,\n",
        "                            operator_number=operator_number,\n",
        "                            transform=transform_operations)\n",
        "\n",
        "number_of_images = dataset.__len__()\n",
        "print(f'lenght {number_of_images}')\n",
        "\n",
        "#train_dataloader\n",
        "# Create a dataloader from the dataset to serve up the images in batches\n",
        "train_dataloader = DataLoader(dataset, \n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=SHUFFLE_T,\n",
        "                        drop_last=True) \n",
        "                        #num_workers=workers)\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(train_dataloader))\n",
        "print(real_batch.shape)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(f'Images from {plane}')\n",
        "grid_images=vutils.make_grid(real_batch.to(device)[:64], nrow=8, padding=2, normalize=True)\n",
        "plt.imshow(np.transpose(grid_images.cpu(),(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7DGOi-rR0aoh",
      "metadata": {
        "id": "7DGOi-rR0aoh"
      },
      "outputs": [],
      "source": [
        "dataset.ref.iloc[:,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OUzvqv_NlJQc",
      "metadata": {
        "id": "OUzvqv_NlJQc"
      },
      "source": [
        "Create a list which includes the all images we selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7h0gB2kYhfPr",
      "metadata": {
        "id": "7h0gB2kYhfPr"
      },
      "outputs": [],
      "source": [
        "all_images = []\n",
        "for idx in range(0, number_of_images):\n",
        "    all_images.append(dataset.ref.iloc[idx, 0])\n",
        "\n",
        "print(all_images)\n",
        "print(len(all_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vaeUp6nElHUO",
      "metadata": {
        "id": "vaeUp6nElHUO"
      },
      "source": [
        "Shuffle the images in this list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4v2Bv8Ze-2H",
      "metadata": {
        "id": "f4v2Bv8Ze-2H"
      },
      "outputs": [],
      "source": [
        "random.shuffle(all_images)  # randomly shuffles the ordering of filenames. random seed = 999\n",
        "print(all_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LvyyCdmolBhc",
      "metadata": {
        "id": "LvyyCdmolBhc"
      },
      "source": [
        "**Split the dataset into train and test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IVjYwg8BlAKe",
      "metadata": {
        "id": "IVjYwg8BlAKe"
      },
      "outputs": [],
      "source": [
        "train_dataset = 0.5\n",
        "\n",
        "split_1 = int(train_dataset * len(all_images))\n",
        "\n",
        "train_images = all_images[:split_1]\n",
        "test_images = all_images[split_1:]\n",
        "\n",
        "print(split_1)\n",
        "\n",
        "print(train_images)\n",
        "print(test_images)\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(test_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PBeG4iAAmdQQ",
      "metadata": {
        "id": "PBeG4iAAmdQQ"
      },
      "source": [
        "Store the train and test dataset into specific folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FX6urPznmcoz",
      "metadata": {
        "id": "FX6urPznmcoz"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "folder_name_train = f\"/content/drive/MyDrive/Original_Images/Train_{plane}_{operator_number}_{us_machine}_{brain_plane}_{image_size}\"  \n",
        "folder_name_test = f\"/content/drive/MyDrive/Original_Images/Test_{plane}_{operator_number}_{us_machine}_{brain_plane}_{image_size}\"  \n",
        "\n",
        "\n",
        "if not os.path.exists(folder_name_train):\n",
        "    os.mkdir(folder_name_train)    #make new folder\n",
        "if not os.path.exists(folder_name_test):\n",
        "    os.mkdir(folder_name_test)    #make new folder\n",
        "\n",
        "\n",
        "for id1 in range(0, len(train_images)):   # copy the train images into the folder\n",
        "    shutil.copy(os.path.join(dataset.root_dir, train_images[id1] + '.png'), folder_name_train)\n",
        "\n",
        "for id2 in range(0, len(test_images)):   # copy the test images into the folder\n",
        "    shutil.copy(os.path.join(dataset.root_dir, test_images[id2] + '.png'), folder_name_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kXwxlWOPwsnK",
      "metadata": {
        "id": "kXwxlWOPwsnK"
      },
      "outputs": [],
      "source": [
        "os.path.join(dataset.root_dir, test_images[2] + '.png')\n",
        "\n",
        "print(sum(os.path.isfile(os.path.join(folder_name_train, name)) for name in os.listdir(folder_name_train)))\n",
        "print(sum(os.path.isfile(os.path.join(folder_name_test, name)) for name in os.listdir(folder_name_test)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
